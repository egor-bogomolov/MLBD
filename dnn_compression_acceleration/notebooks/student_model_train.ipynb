{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data processing</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Model\" data-toc-modified-id=\"Define-Model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Define Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROC-AUC\" data-toc-modified-id=\"ROC-AUC-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>ROC AUC</a></span></li><li><span><a href=\"#Compression-rate\" data-toc-modified-id=\"Compression-rate-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Compression rate</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model\n",
    "\n",
    "\n",
    "Нужно обучть небольшую модель на [soft таргетах](https://drive.google.com/file/d/1tBbPOUT-Ow9f3zTDApykGXYwt-KslYle/view?usp=sharing)  модели учителя, которая не сильно уступала бы в качестве учителю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models.dcn import DCN\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/criteo'\n",
    "\n",
    "TRAIN_DATA = os.path.join(DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Данные на Train/Validation/Test нужно разбить как 80/10/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data loading part was copied from the teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_features_indices = [i for i in range(1, 14)]\n",
    "sparse_features_indices = [i for i in range(14, 40)]\n",
    "\n",
    "dense_features = ['c{}'.format(i) for i in dense_features_indices]\n",
    "sparse_features = ['c{}'.format(i) for i in sparse_features_indices]\n",
    "\n",
    "len(dense_features_indices), len(sparse_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(TRAIN_DATA, index_col='id')\n",
    "data.rename(columns=dict([(col, col[1:] if col[0] == '_' else col) for col in data.columns]), inplace=True)\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "\n",
    "hard_target = ['c0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "soft_targets = pd.read_csv('soft_targets_full.csv', index_col='id', squeeze=True)\n",
    "\n",
    "data['c0_soft'] = soft_targets\n",
    "\n",
    "soft_target = ['c0_soft']\n",
    "targets = hard_target + soft_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>...</th>\n",
       "      <th>c31</th>\n",
       "      <th>c32</th>\n",
       "      <th>c33</th>\n",
       "      <th>c34</th>\n",
       "      <th>c35</th>\n",
       "      <th>c36</th>\n",
       "      <th>c37</th>\n",
       "      <th>c38</th>\n",
       "      <th>c39</th>\n",
       "      <th>c0_soft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5f8f18f</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>f3ddd519</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.532062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1f868fdd</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>7eee76d1</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>9af06ad9</td>\n",
       "      <td>9d93af03</td>\n",
       "      <td>cdfe5ab7</td>\n",
       "      <td>0.483268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1304f63b</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b2853e</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>94bde4f2</td>\n",
       "      <td>010f6491</td>\n",
       "      <td>09b76f8d</td>\n",
       "      <td>0.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>bbf70d82</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16e2e3b3</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>d859b4dd</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.750299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6550.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fa0643ee</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>0094bc78</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>29ece3ed</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>402185f3</td>\n",
       "      <td>0.784883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    c0    c1   c2    c3    c4      c5    c6    c7    c8     c9  ...       c31  \\\n",
       "id                                                              ...             \n",
       "12   1   0.0   -1   0.0   0.0  1465.0   0.0  17.0   0.0    4.0  ...  e5f8f18f   \n",
       "26   1   0.0    1  20.0  16.0  1548.0  93.0  42.0  32.0  912.0  ...  1f868fdd   \n",
       "39   0   8.0    0  15.0  20.0   115.0  24.0   8.0  23.0   24.0  ...  1304f63b   \n",
       "41   1  88.0  319   0.0   4.0     5.0   4.0  89.0  40.0   88.0  ...  bbf70d82   \n",
       "85   0   0.0   53   0.0  10.0  6550.0  98.0  34.0  11.0  349.0  ...  fa0643ee   \n",
       "\n",
       "         c32       c33       c34 c35       c36       c37       c38       c39  \\\n",
       "id                                                                             \n",
       "12        -1        -1  f3ddd519  -1  32c7478e  b34f3128        -1        -1   \n",
       "26  21ddcdc9  a458ea53  7eee76d1  -1  32c7478e  9af06ad9  9d93af03  cdfe5ab7   \n",
       "39  21ddcdc9  b1252a9d  07b2853e  -1  32c7478e  94bde4f2  010f6491  09b76f8d   \n",
       "41        -1        -1  16e2e3b3  -1  32c7478e  d859b4dd        -1        -1   \n",
       "85  21ddcdc9  b1252a9d  0094bc78  -1  32c7478e  29ece3ed  001f3601  402185f3   \n",
       "\n",
       "     c0_soft  \n",
       "id            \n",
       "12  0.532062  \n",
       "26  0.483268  \n",
       "39  0.126496  \n",
       "41  0.750299  \n",
       "85  0.784883  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664931"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processing the categorial features, let's split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931944 366493 366494\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle=False)\n",
    "validation, test = train_test_split(test, test_size=0.5, shuffle=False)\n",
    "\n",
    "print(len(train), len(validation), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features_dims = {feat: len(data[feat].unique()) for feat in sparse_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c14': 1445,\n",
       " 'c15': 556,\n",
       " 'c16': 1130758,\n",
       " 'c17': 360209,\n",
       " 'c18': 304,\n",
       " 'c19': 21,\n",
       " 'c20': 11845,\n",
       " 'c21': 631,\n",
       " 'c22': 3,\n",
       " 'c23': 49223,\n",
       " 'c24': 5194,\n",
       " 'c25': 985420,\n",
       " 'c26': 3157,\n",
       " 'c27': 26,\n",
       " 'c28': 11588,\n",
       " 'c29': 715441,\n",
       " 'c30': 10,\n",
       " 'c31': 4681,\n",
       " 'c32': 2029,\n",
       " 'c33': 4,\n",
       " 'c34': 870796,\n",
       " 'c35': 17,\n",
       " 'c36': 15,\n",
       " 'c37': 87605,\n",
       " 'c38': 84,\n",
       " 'c39': 58187}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High cardinality features\n",
    "\n",
    "We have about 3.6M samples in the dataset. For categorial features with high cardinality there are only a few training examples per each category. It is unlikely that we can learn meaningful high-dimensional embeddings for such categories. Also, such embeddings will consume a lot of memory, even if we apply hashing trick and reduce the number of distinct embedding vectors to 50,000 as it was done for the teacher model. Let's take another approach and encode them with some cool supervised techniques (that's why we split the data beforehand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_features = [feat for feat, cnt in sparse_features_dims.items() if cnt >= 40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c16', 'c17', 'c23', 'c25', 'c29', 'c34', 'c37', 'c39']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatBoostEncoder(a=1,\n",
       "                cols=['c16', 'c17', 'c23', 'c25', 'c29', 'c34', 'c37', 'c39'],\n",
       "                drop_invariant=False, handle_missing='value',\n",
       "                handle_unknown='value', random_state=None, return_df=True,\n",
       "                sigma=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = CatBoostEncoder(cols=high_cardinality_features, verbose=1)\n",
    "enc.fit(train[high_cardinality_features], train[hard_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for df in [train, validation, test]:\n",
    "    df.loc[:, high_cardinality_features] = enc.transform(df.loc[:, high_cardinality_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = dense_features + high_cardinality_features\n",
    "sparse_features = [feat for feat in sparse_features if feat not in high_cardinality_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low cardinality features\n",
    "\n",
    "Now let's deal with low (kind of) cardinality features. For them we will use label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for feat in sparse_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data.loc[:, feat])\n",
    "\n",
    "    for df in [train, validation, test]:\n",
    "        df.loc[:, feat] = le.transform(df.loc[:, feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>...</th>\n",
       "      <th>c31</th>\n",
       "      <th>c32</th>\n",
       "      <th>c33</th>\n",
       "      <th>c34</th>\n",
       "      <th>c35</th>\n",
       "      <th>c36</th>\n",
       "      <th>c37</th>\n",
       "      <th>c38</th>\n",
       "      <th>c39</th>\n",
       "      <th>c0_soft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>4211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365174</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267092</td>\n",
       "      <td>0.532062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.047188</td>\n",
       "      <td>...</td>\n",
       "      <td>588</td>\n",
       "      <td>248</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.496607</td>\n",
       "      <td>52</td>\n",
       "      <td>0.506555</td>\n",
       "      <td>0.483268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>...</td>\n",
       "      <td>354</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156868</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313736</td>\n",
       "      <td>0.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>...</td>\n",
       "      <td>3393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211829</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267092</td>\n",
       "      <td>0.750299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>...</td>\n",
       "      <td>4577</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.383206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311325</td>\n",
       "      <td>0.784883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    c0        c1        c2        c3        c4        c5        c6        c7  \\\n",
       "id                                                                             \n",
       "12   1  0.000000  0.000091  0.000000  0.000000  0.000558  0.000000  0.001717   \n",
       "26   1  0.000000  0.000181  0.000305  0.018244  0.000590  0.000798  0.004242   \n",
       "39   0  0.001385  0.000136  0.000229  0.022805  0.000044  0.000206  0.000808   \n",
       "41   1  0.015238  0.014591  0.000000  0.004561  0.000002  0.000034  0.008989   \n",
       "85   0  0.000000  0.002537  0.000000  0.011403  0.002497  0.000841  0.003434   \n",
       "\n",
       "          c8        c9  ...   c31  c32  c33       c34  c35  c36       c37  \\\n",
       "id                      ...                                                 \n",
       "12  0.000000  0.000207  ...  4211    0    0  0.365174    0    2  0.260759   \n",
       "26  0.006335  0.047188  ...   588  248    2  0.254942    0    2  0.496607   \n",
       "39  0.004554  0.001242  ...   354  248    3  0.254942    0    2  0.156868   \n",
       "41  0.007919  0.004553  ...  3393    0    0  0.211829    0    2  0.230221   \n",
       "85  0.002178  0.018058  ...  4577  248    3  0.254942    0    2  0.383206   \n",
       "\n",
       "    c38       c39   c0_soft  \n",
       "id                           \n",
       "12    0  0.267092  0.532062  \n",
       "26   52  0.506555  0.483268  \n",
       "39    2  0.313736  0.126496  \n",
       "41    0  0.267092  0.750299  \n",
       "85    1  0.311325  0.784883  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, prepare input for the model (mostly copied from the teacher model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, \n",
    "                                     vocabulary_size=vocab_size, \n",
    "                                     embedding_dim=min(int(6 * (vocab_size) ** (0.25)), 100), \n",
    "                                     use_hash=False, dtype='string') \n",
    "                          for feat, vocab_size in sparse_features_dims.items()] + \\\n",
    "                        [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input(df):\n",
    "    return {name: (pd.core.series.Series(df[name]) if name in sparse_features else np.array(df[name])) for name in feature_names}\n",
    "\n",
    "\n",
    "train_model_input = gen_model_input(train)\n",
    "validation_model_input = gen_model_input(validation)\n",
    "test_model_input = gen_model_input(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_targets = train[targets]\n",
    "validation_model_targets = validation[targets]\n",
    "test_model_targets = test[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Можно также использовать Pruning и/или Quantinization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first solution let's use the same model as the teacher (DCN) but with smaller number of parameters.\n",
    "\n",
    "To do so, we should redefine the loss function to use both soft and hard targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(y_pred, y_true, weight=0.99):\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    loss_hard = F.binary_cross_entropy(y_pred, y_true[:, 0], reduction='sum')\n",
    "    loss_soft = F.binary_cross_entropy(y_pred, y_true[:, 1], reduction='sum')\n",
    "    return weight * loss_soft + (1 - weight) * loss_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 286176400 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-83be2d7b04d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mdnn_hidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_linear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0ml2_reg_cross\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_dnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             dnn_use_bn=True, dnn_activation='relu', task='binary')\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistillation_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepctr_torch/models/dcn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, linear_feature_columns, dnn_feature_columns, cross_num, dnn_hidden_units, l2_reg_linear, l2_reg_embedding, l2_reg_cross, l2_reg_dnn, init_std, seed, dnn_dropout, dnn_activation, dnn_use_bn, task, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m                                   \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                   \u001b[0mdnn_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_activation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                                   task=task, device=device)\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn_hidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_hidden_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, linear_feature_columns, dnn_feature_columns, dnn_hidden_units, l2_reg_linear, l2_reg_embedding, l2_reg_dnn, init_std, seed, dnn_dropout, dnn_activation, task, device)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn_feature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_feature_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m#         nn.ModuleDict(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m#             {feat.embedding_name: nn.Embedding(feat.dimension, embedding_size, sparse=True) for feat in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36mcreate_embedding_matrix\u001b[0;34m(feature_columns, init_std, linear, sparse, device)\u001b[0m\n\u001b[1;32m    167\u001b[0m         {feat.embedding_name: nn.Embedding(feat.vocabulary_size, feat.embedding_dim if not linear else 1, sparse=sparse)\n\u001b[1;32m    168\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m          sparse_feature_columns + varlen_sparse_feature_columns}\n\u001b[0m\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m     embedding_dict = nn.ModuleDict(\n\u001b[1;32m    167\u001b[0m         {feat.embedding_name: nn.Embedding(feat.vocabulary_size, feat.embedding_dim if not linear else 1, sparse=sparse)\n\u001b[0;32m--> 168\u001b[0;31m          \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m          sparse_feature_columns + varlen_sparse_feature_columns}\n\u001b[1;32m    170\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 286176400 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "model = DCN(linear_feature_columns, dnn_feature_columns, cross_num=2,\n",
    "            dnn_hidden_units=(32, 32), l2_reg_linear=0, l2_reg_embedding=0,\n",
    "            l2_reg_cross=0, l2_reg_dnn=0, init_std=0.0001, seed=1024, \n",
    "            dnn_use_bn=True, dnn_activation='relu', task='binary')\n",
    "\n",
    "model.compile(\"adam\", distillation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ad3ac25bc335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_model_input, train_model_targets.values, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Наша основная задача получить модель, которая \n",
    "* в терминах ROC AUC не намного хуже модели учителя, и в то же время \n",
    "* сильно меньше по размеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "Сравним ROC AUC модели ученика с показателем для учителя.\n",
    "\n",
    "ROC AUC учителя: 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate\n",
    "\n",
    "Пусть \n",
    "* $a$ - \\# of the parameters in the original model $M$\n",
    "* $a^{*}$ - \\# of the parameters in compressed model $M^{*}$\n",
    "\n",
    "тогда compression rate is $$\\alpha(M,M^{*}) = \\frac{a}{a^{*}}$$\n",
    "\n",
    "Можно также посчитать comression rate просто как отношение фактических размеров моделей.\n",
    "\n",
    "Размер модели учителя - 168MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
